{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m---> 52\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy, \n\u001b[0;32m     53\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[0;32m     54\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Display model summary\u001b[39;00m\n\u001b[0;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras import optimizers, regularizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import (\n",
    "    Dense, Activation, Flatten, Conv2D, MaxPooling2D, \n",
    "    Dropout, BatchNormalization, Lambda\n",
    ")\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()\n",
    "\n",
    "# Normalize data\n",
    "train_X = train_X.astype('float32') / 255\n",
    "test_X = test_X.astype('float32') / 255\n",
    "\n",
    "# One-hot encode labels\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy, \n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_X, \n",
    "    train_Y_one_hot, \n",
    "    batch_size=64, \n",
    "    epochs=100, \n",
    "    validation_data=(test_X, test_Y_one_hot)\n",
    ")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(\n",
    "    test_X[0:100], \n",
    "    test_Y_one_hot[0:100], \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Print the test accuracy\n",
    "print('\\nKeras CNN Test Accuracy:', score[1], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filters and biases of the first convolutional layer\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "# Visualize the first 5 filters\n",
    "for i in range(5):\n",
    "    plt.imshow(filters[:, :, 0, i], cmap='gray')\n",
    "    plt.title(f'Filter {i+1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# Select an image from the training set\n",
    "im = train_X[10]\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Perform convolution using one of the filters\n",
    "output = signal.convolve2d(\n",
    "    im.reshape(32, 32, 3)[:, :, 0],  # Using the first channel for grayscale effect\n",
    "    filters[:, :, 0, 1].reshape(3, 3), \n",
    "    boundary='symm', \n",
    "    mode='same'\n",
    ")\n",
    "\n",
    "# Display the convolved image\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.title('After Convolution')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "train_X = train_X.astype('float32') / 255\n",
    "test_X = test_X.astype('float32') / 255\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Design the fully connected neural network\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model with training and validation sets\n",
    "history = model.fit(\n",
    "    train_X, \n",
    "    train_Y_one_hot, \n",
    "    batch_size=64, \n",
    "    epochs=20, \n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    "# Display test metrics\n",
    "print(f'\\nTest Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
